
1. Dimensionality :-

   Dimensionality refers to the number of features (columns or variables) in a dataset.

   For example, a dataset with 5 features has 5 dimensions.

2. Why Dimensionality Reduction ?

  | Reason                       | Description                                                         |
  | ---------------------------- | ------------------------------------------------------------------- |
  |  **Simplify models**        | Reduces the number of variables → makes models easier to understand  |
  |  **Improve performance**   | Fewer features = faster processing and training                       |
  |  **Avoid overfitting**     | Reduces noise and irrelevant features                                 |
  |  **Focus on key features** | Keeps only the features that explain most of the variation            |
  |  **Visualize data**        | Makes it possible to **plot high-dimensional data** in 2D or 3D       |

3. Principal Component Analysis :-

   PCA is a linear combination of features where minimalistic features are covering a large proportional variance."

   Expalanation:-

   1. Linear Combination Of features - PCA transforms the original features (columns) into new features (called principal
     
      components) 

   2. Minimalistic Features :-

      We don’t need all original features — just a few principal components (e.g., 2 or 3) that retain most of the information.

   3. Covering a large proportional Variance :-

      These few components explain most of the variation (differences) in the data. 

      